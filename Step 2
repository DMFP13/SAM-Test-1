# Step 1: Install dependencies
!pip install torch torchvision
!pip install git+https://github.com/facebookresearch/segment-anything.git
!pip install opencv-python-headless

# Step 2: Import necessary libraries
import os
import torch
from segment_anything import sam_model_registry, SamPredictor
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from torchvision import transforms
import torchvision.models as models
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset

# Step 3: Load the SAM model
model_checkpoint = "/content/drive/MyDrive/Data Sets for Collab/SAM PTH/sam_vit_h_4b8939.pth"

# Check if the model checkpoint file exists
if not os.path.exists(model_checkpoint):
    raise FileNotFoundError(f"The model checkpoint file was not found at {model_checkpoint}. Please verify the path.")

sam = sam_model_registry["vit_h"](checkpoint=model_checkpoint)

# Step 4: Create the predictor
device = "cuda" if torch.cuda.is_available() else "cpu"
sam.to(device)
predictor = SamPredictor(sam)

# Step 5: Specify directories with images
back_view_dir = "/content/drive/MyDrive/Data Sets for Collab/Cattle side view and back view dataset/Cattle side and back view images/back view"
side_view_dir = "/content/drive/MyDrive/Data Sets for Collab/Cattle side view and back view dataset/Cattle side and back view images/side view"

# Step 6: Define a function to process images and extract masks
def process_images(image_dir):
    images = []
    masks = []
    
    for image_name in os.listdir(image_dir):
        if image_name.endswith(".png"):
            # Load the image
            image_path = os.path.join(image_dir, image_name)
            image = Image.open(image_path)
            image_np = np.array(image)

            # Set the image for prediction
            predictor.set_image(image_np)

            # Use a center point prompt to identify the cow
            input_point = np.array([[image_np.shape[1] // 2, image_np.shape[0] // 2]])
            input_label = np.array([1])

            masks_pred, _, _ = predictor.predict(point_coords=input_point, point_labels=input_label, multimask_output=False)

            # Resize the image and mask to ensure consistent dimensions
            image_resized = cv2.resize(image_np, (224, 224))
            mask_resized = cv2.resize(masks_pred[0].astype(np.uint8), (224, 224))

            # Save the resized image and mask
            images.append(image_resized)
            masks.append(mask_resized)
    
    return images, masks

# Step 7: Process both directories
back_view_images, back_view_masks = process_images(back_view_dir)
side_view_images, side_view_masks = process_images(side_view_dir)

# Combine both sets of images and masks
all_images = back_view_images + side_view_images
all_masks = back_view_masks + side_view_masks

# Step 8: Prepare the dataset for training a cow recognition model
class CowDataset(Dataset):
    def __init__(self, images, masks, transform=None):
        self.images = images
        self.masks = masks
        self.transform = transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = self.images[idx]
        mask = self.masks[idx]
        
        # Convert image and mask to PIL images
        image = Image.fromarray(image)
        mask = Image.fromarray((mask * 255).astype(np.uint8))

        if self.transform:
            image = self.transform(image)
            mask = transforms.ToTensor()(mask)  # Ensure mask is a tensor

        # Create a label: 1 if there's a significant amount of cow, 0 otherwise
        label = (mask.sum() > (0.1 * mask.numel())).float().unsqueeze(0)  # Set label to 1 if at least 10% of the pixels are cow

        return image, label

# Define transformations for the images
transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.ToTensor(),
])

# Split the data into training and validation sets
train_images, val_images, train_masks, val_masks = train_test_split(all_images, all_masks, test_size=0.2, random_state=42)

# Create datasets and data loaders
train_dataset = CowDataset(train_images, train_masks, transform=transform)
val_dataset = CowDataset(val_images, val_masks, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)

# Step 9: Define the cow recognition model
model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
model.fc = nn.Sequential(
    nn.Dropout(0.6),
    nn.Linear(model.fc.in_features, 1)
)
model = model.to(device)

# Step 10: Set up the training loop
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)

num_epochs = 30
best_accuracy = 0.0
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    scheduler.step()  # Update the learning rate

    # Validation phase
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

            predicted = (torch.sigmoid(outputs) > 0.5).float()
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = correct / total
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        torch.save(model.state_dict(), "/content/drive/MyDrive/Data Sets for Collab/cow_recognition_model_best.pth")

    print(f"Epoch [{epoch+1}/{num_epochs}], Training Loss: {running_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {accuracy:.4f}")

    # Stop early if accuracy reaches 90%
    if accuracy >= 0.9:
        print("Reached 90% validation accuracy, stopping training early.")
        break

# Step 11: Save the final model
torch.save(model.state_dict(), "/content/drive/MyDrive/Data Sets for Collab/cow_recognition_model.pth")
