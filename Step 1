# Step 1: Install dependencies
!pip install torch torchvision
!pip install git+https://github.com/facebookresearch/segment-anything.git

# Step 2: Import necessary libraries
import os
import torch
from segment_anything import sam_model_registry, SamPredictor
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

# Step 3: Load the SAM model
# Update this path with your own downloaded SAM checkpoint
model_checkpoint = "/content/drive/MyDrive/Data Sets for Collab/SAM PTH/sam_vit_h_4b8939.pth"
sam = sam_model_registry["vit_h"](checkpoint=model_checkpoint)

# Step 4: Create the predictor
device = "cuda" if torch.cuda.is_available() else "cpu"
sam.to(device)
predictor = SamPredictor(sam)

# Step 5: Specify the directory with the images
image_dir = "/content/drive/MyDrive/Data Sets for Collab/Cattle side view and back view dataset/Cattle side and back view images/back view"

# Step 6: Analyze the images using SAM
for image_name in os.listdir(image_dir):
    if image_name.endswith(".png"):
        # Load the image
        image_path = os.path.join(image_dir, image_name)
        image = Image.open(image_path)
        image_np = np.array(image)

        # Set the image for prediction
        predictor.set_image(image_np)

        # Assuming you want to predict masks using point prompts
        # You can modify this to use different types of prompts as needed
        input_point = np.array([[image_np.shape[1] // 2, image_np.shape[0] // 2]])
        input_label = np.array([1])

        masks, _, _ = predictor.predict(point_coords=input_point, point_labels=input_label, multimask_output=True)

        # Plot the results
        fig, ax = plt.subplots(1, len(masks) + 1, figsize=(10, 5))
        ax[0].imshow(image)
        ax[0].set_title("Original Image")

        for i, mask in enumerate(masks):
            ax[i + 1].imshow(mask, cmap='viridis')
            ax[i + 1].set_title(f"Mask {i+1}")

        plt.show()
